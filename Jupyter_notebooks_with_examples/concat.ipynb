{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283248c7",
   "metadata": {},
   "source": [
    "## Concatenate DataFrame columns\n",
    "Using concat() or concat_ws() Spark SQL functions we can concatenate one or more DataFrame columns into a single column.\n",
    "\n",
    "## Test Data and Dataframe\n",
    "Note that we need to import implicits on `spark` object which is an instance of SparkSession in order to use toDF() on Seq collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e98610bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+--------+------+------+\n",
      "|fname |mname|lname   |dob_year|gender|salary|\n",
      "+------+-----+--------+--------+------+------+\n",
      "|Jason |B    |Williams|2017    |M     |4000  |\n",
      "|Maria |Rose |Jones   |2009    |M     |4500  |\n",
      "|Rob   |J    |Smith   |2009    |M     |5000  |\n",
      "|Gloria|Mery |Jones   |2005    |F     |5500  |\n",
      "|Sean  |K    |Brown   |2006    |      |-1    |\n",
      "+------+-----+--------+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from termcolor import cprint \n",
    "\n",
    "spark = SparkSession.builder.appName('concat').getOrCreate()\n",
    "\n",
    "data = [(\"Jason\",\"B\",\"Williams\",\"2017\",\"M\",4000),\n",
    "        (\"Maria\",\"Rose\",\"Jones\",\"2009\",\"M\",4500),\n",
    "        (\"Rob\",\"J\",\"Smith\",\"2009\",\"M\",5000),\n",
    "        (\"Gloria\",\"Mery\",\"Jones\",\"2005\",\"F\",5500),\n",
    "        (\"Sean\",\"K\",\"Brown\",\"2006\",\"\",-1)\n",
    "       ]\n",
    "\n",
    "columns = [\"fname\",\"mname\",\"lname\",\"dob_year\",\"gender\",\"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42723973",
   "metadata": {},
   "source": [
    "### Using concat() Function to Concatenate DataFrame Columns\n",
    "Spark SQL functions provide `concat()` to concatenate two or more DataFrame columns into a single Column.\n",
    "\n",
    "Syntax\n",
    "\n",
    "    concat(exprs: Column*): Column\n",
    "    \n",
    "It can also take columns of different Data Types and concatenate them into a single column. for example, it supports String, Int, Boolean and also arrays.\n",
    "\n",
    "This statement creates `FullName` column by concatenating columns `fname`, `mname`, `lname` separating by delimiter comma. To add a delimiter, we have used `lit()` function. This yields output with just a concatenated column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a208e7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|FullName           |\n",
      "+-------------------+\n",
      "|Jason, B, Williams |\n",
      "|Maria, Rose, Jones |\n",
      "|Rob, J, Smith      |\n",
      "|Gloria, Mery, Jones|\n",
      "|Sean, K, Brown     |\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat, lit\n",
    "\n",
    "df.select(concat(col(\"fname\"),lit(', '),col(\"mname\"),lit(', '),col(\"lname\")).alias(\"FullName\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259130d8",
   "metadata": {},
   "source": [
    "### concat() Function on withColumn()\n",
    "we will add a new column `FullName` by concatenating columns names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e508999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+--------+------+------+-----------------+\n",
      "|fname |mname|lname   |dob_year|gender|salary|FullName         |\n",
      "+------+-----+--------+--------+------+------+-----------------+\n",
      "|Jason |B    |Williams|2017    |M     |4000  |Jason,B,Williams |\n",
      "|Maria |Rose |Jones   |2009    |M     |4500  |Maria,Rose,Jones |\n",
      "|Rob   |J    |Smith   |2009    |M     |5000  |Rob,J,Smith      |\n",
      "|Gloria|Mery |Jones   |2005    |F     |5500  |Gloria,Mery,Jones|\n",
      "|Sean  |K    |Brown   |2006    |      |-1    |Sean,K,Brown     |\n",
      "+------+-----+--------+--------+------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"FullName\",concat(col(\"fname\"),lit(','), col(\"mname\"),lit(','),col(\"lname\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b965a7",
   "metadata": {},
   "source": [
    "The above snippet also keeps the individual names, if you do not need it you can `drop()` them using the below statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5ce20d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+-----------------+\n",
      "|dob_year|gender|salary|FullName         |\n",
      "+--------+------+------+-----------------+\n",
      "|2017    |M     |4000  |Jason,B,Williams |\n",
      "|2009    |M     |4500  |Maria,Rose,Jones |\n",
      "|2009    |M     |5000  |Rob,J,Smith      |\n",
      "|2005    |F     |5500  |Gloria,Mery,Jones|\n",
      "|2006    |      |-1    |Sean,K,Brown     |\n",
      "+--------+------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"FullName\",concat(col(\"fname\"),lit(','), col(\"mname\"),lit(','),col(\"lname\"))) \\\n",
    "    .drop(\"fname\").drop(\"mname\").drop(\"lname\") \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de878ec",
   "metadata": {},
   "source": [
    "### Using concat_ws() Function to Concatenate with Delimiter\n",
    "Adding a delimiter while concatenating DataFrame columns can be easily done using another function `concat_ws()`.\n",
    "\n",
    "syntax\n",
    "\n",
    "    concat_ws(sep: String, exprs: Column*): Column\n",
    "\n",
    "`concat_ws()` function takes the first argument as delimiter following with columns that need to concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0feece38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+-------------------+\n",
      "|dob_year|gender|salary|FullName           |\n",
      "+--------+------+------+-------------------+\n",
      "|2017    |M     |4000  |Jason ,B ,Williams |\n",
      "|2009    |M     |4500  |Maria ,Rose ,Jones |\n",
      "|2009    |M     |5000  |Rob ,J ,Smith      |\n",
      "|2005    |F     |5500  |Gloria ,Mery ,Jones|\n",
      "|2006    |      |-1    |Sean ,K ,Brown     |\n",
      "+--------+------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "df.withColumn(\"FullName\",concat_ws(\" ,\",col(\"fname\"),col(\"mname\"),col(\"lname\"))) \\\n",
    "    .drop(\"fname\").drop(\"mname\").drop(\"lname\") \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0f837",
   "metadata": {},
   "source": [
    "### Using Raw SQL\n",
    "Spark SQL provides a way to concatenate using Raw SQL syntax. But In order to use this first you need to create a temporary view using `df.createOrReplaceTempView(\"TMP\")`. This creates a temporary table \"TMP\".\n",
    "\n",
    "We can use `concat(`) function on the raw SQL statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48c9382c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|FullName         |\n",
      "+-----------------+\n",
      "|Jason Williams B |\n",
      "|Maria Jones Rose |\n",
      "|Rob Smith J      |\n",
      "|Gloria Jones Mery|\n",
      "|Sean Brown K     |\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"TMP\")\n",
    "\n",
    "spark.sql(\"select CONCAT(fname,' ',lname,' ',mname) as FullName from TMP\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
