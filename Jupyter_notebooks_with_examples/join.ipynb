{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f59215b1",
   "metadata": {},
   "source": [
    "## Join Syntax\n",
    "PySpark SQL join has a below syntax and it can be accessed directly from DataFrame.\n",
    "\n",
    "    join(self, other, on=None, how=None)\n",
    "\n",
    "       * other: Right side of the join\n",
    "       * on: a string for the join column name\n",
    "       * how: default `inner`. Must be one of `inner`, `cross`, `outer`,`full`, `full_outer`, `left`, `left_outer`, `right`, `right_outer`,`left_semi`, and `left_anti`.\n",
    "\n",
    "You can also write Join expression by adding where() and filter() methods on DataFrame and can have Join on multiple columns.\n",
    "`join()` operation takes parameters as below and returns DataFrame.\n",
    "\n",
    "\n",
    "### PySpark Join Types\n",
    "\n",
    "| Join String | Equivalent SQL Join |\n",
    "| :- | -: |\n",
    "|inner\t| INNER JOIN |\n",
    "|outer, full, fullouter, full_outer\t| FULL OUTER JOIN |\n",
    "|left, leftouter, left_outer |\tLEFT JOIN |\n",
    "|right, rightouter, right_outer\t| RIGHT JOIN |\n",
    "|cross\t | |\n",
    "|anti, leftanti, left_anti\t | |\n",
    "|semi, leftsemi, left_semi\t | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d821ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from termcolor import cprint \n",
    "\n",
    "spark = SparkSession.builder.appName('join').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38863f7",
   "metadata": {},
   "source": [
    "let’s create an `emp` and `dept` DataFrames. here, column `emp_id` is unique on emp and `dept_id` is unique on the dept dataset’s and emp_dept_id from emp has a reference to dept_id on dept dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a27b7a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superior_emp_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- emp_dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "\u001b[34m--- Emp Dataset\u001b[0m\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n",
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n",
      "\u001b[34m--- Dept Dataset\u001b[0m\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "       (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
    "       (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
    "       (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
    "       (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
    "       (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\\n",
    "     ]\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \\\n",
    "              \"emp_dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
    "empDF.printSchema()\n",
    "cprint(\"--- Emp Dataset\", \"blue\")\n",
    "empDF.show(truncate=False)\n",
    "\n",
    "dept = [(\"Finance\",10), \\\n",
    "    (\"Marketing\",20), \\\n",
    "    (\"Sales\",30), \\\n",
    "    (\"IT\",40) \\\n",
    "  ]\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "deptDF.printSchema()\n",
    "cprint(\"--- Dept Dataset\", \"blue\")\n",
    "deptDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a082d",
   "metadata": {},
   "source": [
    "### Inner Join DataFrame\n",
    "`Inner` join is the default join in PySpark and it’s mostly used. This joins two datasets on key columns, where keys don’t match the rows get dropped from both datasets (`emp` & `dept`).\n",
    "\n",
    "When we apply Inner join on our datasets, It drops `emp_dept_id` 50 from `emp` and `dept_id` 30 from `dept` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3b0f2aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"inner\") \\\n",
    "     .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d657d68",
   "metadata": {},
   "source": [
    "### Full Outer Join\n",
    "`Outer` a.k.a `full`, `fullouter` join returns all rows from both datasets, where join expression doesn’t match it returns null on respective record columns.\n",
    "\n",
    "From our `emp` dataset’s `emp_dept_id` with value 50 doesn’t have a record on `dept` hence dept columns have null and `dept_id` 30 doesn’t have a record in `emp` hence you see null’s on emp columns. Below is the result of the above Join expression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "589f381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m--- empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"outer\")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|NULL  |NULL    |NULL           |NULL       |NULL       |NULL  |NULL  |Sales    |30     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |NULL     |NULL   |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "\u001b[31m--- empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"full\")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|NULL  |NULL    |NULL           |NULL       |NULL       |NULL  |NULL  |Sales    |30     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |NULL     |NULL   |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "\u001b[31m--- empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"fullouter\")\u001b[0m\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|NULL  |NULL    |NULL           |NULL       |NULL       |NULL  |NULL  |Sales    |30     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |NULL     |NULL   |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cprint('--- empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"outer\")', \"red\")\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"outer\").show(truncate=False)\n",
    "cprint('--- empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"full\")', \"red\")\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"full\").show(truncate=False)\n",
    "cprint('--- empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"fullouter\")', \"red\")\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"fullouter\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d71a9f",
   "metadata": {},
   "source": [
    "### Left Outer Join\n",
    "`Left` a.k.a `Leftouter` join returns all rows from the left dataset regardless of match found on the right dataset when join expression doesn’t match, it assigns null for that record and drops records from right where match not found.\n",
    "\n",
    "From our dataset, `emp_dept_id` 50 doesn’t have a record on `dept` dataset hence, this record contains null on `dept` columns (dept_name & dept_id). and `dept_id` 30 from `dept` dataset dropped from the results. Below is the result of the above Join expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37fbd82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m--- empDF.join(deptDF,emp_dept_id ==  deptDF.dept_id,\"left\")\u001b[0m\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |NULL     |NULL   |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "\u001b[31m--- empDF.join(deptDF,emp_dept_id ==  deptDF.dept_id,\"leftouter\")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |NULL     |NULL   |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cprint('--- empDF.join(deptDF,emp_dept_id ==  deptDF.dept_id,\"left\")', \"red\")\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"left\").show(truncate=False)\n",
    "cprint('--- empDF.join(deptDF,emp_dept_id ==  deptDF.dept_id,\"leftouter\")', \"red\")\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftouter\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efacd77c",
   "metadata": {},
   "source": [
    "### Right Outer Join\n",
    "`Right` a.k.a `Rightouter` join is opposite of `left` join, here it returns all rows from the right dataset regardless of math found on the left dataset, when join expression doesn’t match, it assigns null for that record and drops records from left where match not found.\n",
    "\n",
    "the right dataset `dept_id` 30 doesn’t have it on the left dataset `emp` hence, this record contains null on `emp` columns. and `emp_dept_id` 50 dropped as a match not found on left. Below is the result of the above Join expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "267b6bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m--- empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"right\")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|NULL  |NULL    |NULL           |NULL       |NULL       |NULL  |NULL  |Sales    |30     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "\u001b[31m--- empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"rightouter\")\u001b[0m\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|NULL  |NULL    |NULL           |NULL       |NULL       |NULL  |NULL  |Sales    |30     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cprint('--- empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"right\")', \"red\")\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"right\").show(truncate=False)\n",
    "cprint('--- empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"rightouter\")', \"red\")\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"rightouter\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49597b",
   "metadata": {},
   "source": [
    "### Left Semi Join\n",
    "`leftsemi` join is similar to `inner` join, the difference being `leftsemi` join returns all columns from the left dataset and ignores all columns from the right dataset. In other words, this join returns columns from the only left dataset for the records match in the right dataset on join expression, records not matched on join expression are ignored from both left and right datasets.\n",
    "\n",
    "The same result can be achieved using select on the result of the inner join however, using this join would be efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ad1a510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftsemi\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f4f17b",
   "metadata": {},
   "source": [
    "### Left Anti Join\n",
    "`leftanti` join does the exact opposite of the `leftsemi`, `leftanti` join returns only columns from the left dataset for non-matched records.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c03880dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|6     |Brown|2              |2010       |50         |      |-1    |\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftanti\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5845fbe",
   "metadata": {},
   "source": [
    "### Self Join\n",
    "Joins are not complete without a self join, Though there is no self-join type available, we can use any of the above-explained join types to join DataFrame to itself. below example use `inner` self join.\n",
    "\n",
    "Here, we are joining `emp` dataset with itself to find out superior `emp_id` and `name` for all employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d1aaf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------------+\n",
      "|emp_id|name    |superior_emp_id|superior_emp_name|\n",
      "+------+--------+---------------+-----------------+\n",
      "|2     |Rose    |1              |Smith            |\n",
      "|3     |Williams|1              |Smith            |\n",
      "|4     |Jones   |2              |Rose             |\n",
      "|5     |Brown   |2              |Rose             |\n",
      "|6     |Brown   |2              |Rose             |\n",
      "+------+--------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.alias(\"emp1\").join(empDF.alias(\"emp2\"), col(\"emp1.superior_emp_id\") == col(\"emp2.emp_id\"),\"inner\") \\\n",
    "    .select(col(\"emp1.emp_id\"),col(\"emp1.name\"), col(\"emp2.emp_id\").alias(\"superior_emp_id\"), \\\n",
    "            col(\"emp2.name\").alias(\"superior_emp_name\")) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d1e309",
   "metadata": {},
   "source": [
    "### Using SQL Expression\n",
    "Since PySpark SQL support native SQL syntax, we can also write join operations after creating temporary tables on DataFrames and use these tables on `spark.sql()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0394eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.createOrReplaceTempView(\"EMP\")\n",
    "deptDF.createOrReplaceTempView(\"DEPT\")\n",
    "\n",
    "joinDF = spark.sql(\"select * from EMP e, DEPT d where e.emp_dept_id == d.dept_id\").show(truncate=False)\n",
    "\n",
    "joinDF2 = spark.sql(\"select * from EMP e INNER JOIN DEPT d ON e.emp_dept_id == d.dept_id\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd769b",
   "metadata": {},
   "source": [
    "### SQL Join on multiple DataFrames\n",
    "When you need to join more than two tables, you either use SQL expression after creating a temporary view on the DataFrame or use the result of join operation to join with another DataFrame like chaining them.\n",
    "    \n",
    "    df1.join(df2,df1.id1 == df2.id2,\"inner\").join(df3,df1.id1 == df3.id3,\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e0201",
   "metadata": {},
   "source": [
    "### Finding difference between dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a4bcffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superiorid: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "\u001b[34m--- currentDF Dataset\u001b[0m\n",
      "+---+--------+----------+-----------+-------+------+------+\n",
      "|id |name    |superiorid|year_joined|dept_id|gender|salary|\n",
      "+---+--------+----------+-----------+-------+------+------+\n",
      "|1  |Smith   |-1        |2018       |10     |M     |3000  |\n",
      "|2  |Rose    |1         |2010       |20     |M     |4000  |\n",
      "|3  |Williams|1         |2010       |10     |M     |1000  |\n",
      "|4  |Jones   |2         |2005       |10     |F     |2000  |\n",
      "|5  |Brown   |2         |2010       |40     |      |-1    |\n",
      "|6  |Brown   |2         |2010       |50     |      |-1    |\n",
      "+---+--------+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current = [ (1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "            (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
    "            (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
    "            (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
    "            (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
    "            (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\\n",
    "            ]\n",
    "currentColumns = [\"id\",\"name\",\"superiorid\",\"year_joined\", \"dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "currentDF = spark.createDataFrame(data=current, schema = currentColumns)\n",
    "currentDF.printSchema()\n",
    "cprint(\"--- currentDF Dataset\", \"blue\")\n",
    "currentDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b262d600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superiorid: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "\u001b[31m--- previousDF Dataset\u001b[0m\n",
      "+---+-----+----------+-----------+-------+------+------+\n",
      "|id |name |superiorid|year_joined|dept_id|gender|salary|\n",
      "+---+-----+----------+-----------+-------+------+------+\n",
      "|1  |Smith|-1        |2018       |10     |M     |3000  |\n",
      "|2  |Rose |1         |2010       |20     |M     |4000  |\n",
      "|3  |Will |1         |2010       |10     |M     |1000  |\n",
      "|4  |Jones|2         |2005       |10     |F     |2500  |\n",
      "|5  |Brown|2         |2010       |40     |      |-1    |\n",
      "|6  |Brown|2         |2010       |50     |      |-1    |\n",
      "+---+-----+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previous = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "            (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
    "            (3,\"Will\",1,\"2010\",\"10\",\"M\",1000), \\\n",
    "            (4,\"Jones\",2,\"2005\",\"10\",\"F\",2500), \\\n",
    "            (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
    "            (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\\n",
    "            ]\n",
    "previousColumns = [\"id\",\"name\",\"superiorid\",\"year_joined\", \"dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "previousDF = spark.createDataFrame(data=previous, schema = previousColumns)\n",
    "previousDF.printSchema()\n",
    "cprint(\"--- previousDF Dataset\", \"red\")\n",
    "previousDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f61c9c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+-----------+-------+------+------+\n",
      "|id |name    |superiorid|year_joined|dept_id|gender|salary|\n",
      "+---+--------+----------+-----------+-------+------+------+\n",
      "|3  |Williams|1         |2010       |10     |M     |1000  |\n",
      "|4  |Jones   |2         |2005       |10     |F     |2000  |\n",
      "+---+--------+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = currentDF.subtract(previousDF)\n",
    "df_test.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93a62d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+-----------+-------+------+------+\n",
      "|id |name |superiorid|year_joined|dept_id|gender|salary|\n",
      "+---+-----+----------+-----------+-------+------+------+\n",
      "|4  |Jones|2         |2005       |10     |F     |2500  |\n",
      "|3  |Will |1         |2010       |10     |M     |1000  |\n",
      "+---+-----+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test2 = previousDF.subtract(currentDF)\n",
    "df_test2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d17ca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+-----------+-------+------+------+\n",
      "|name|id |superiorid|year_joined|dept_id|gender|salary|\n",
      "+----+---+----------+-----------+-------+------+------+\n",
      "|Will|3  |1         |2010       |10     |M     |1000  |\n",
      "+----+---+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_test3 = previousDF.join(currentDF, on='name', how='left_anti')\n",
    "df_test3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d67dc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----+----------+-----------+-------+------+\n",
      "|salary|id |name |superiorid|year_joined|dept_id|gender|\n",
      "+------+---+-----+----------+-----------+-------+------+\n",
      "|2500  |4  |Jones|2         |2005       |10     |F     |\n",
      "+------+---+-----+----------+-----------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test4 = previousDF.join(currentDF, on='salary', how='left_anti')\n",
    "df_test4.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11811eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+-----------+-------+------+------+\n",
      "|id |name |superiorid|year_joined|dept_id|gender|salary|\n",
      "+---+-----+----------+-----------+-------+------+------+\n",
      "|3  |Will |1         |2010       |10     |M     |1000  |\n",
      "|4  |Jones|2         |2005       |10     |F     |2500  |\n",
      "+---+-----+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_test5 = previousDF.exceptAll(currentDF)\n",
    "df_test5.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a867df",
   "metadata": {},
   "source": [
    "### Complex dataframes differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f29df86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- full name: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- superiorid: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "\u001b[34m--- currentDF Dataset\u001b[0m\n",
      "+---+----------------+----------+-----------+-------+------+------+\n",
      "|id |full name       |superiorid|year_joined|dept_id|gender|salary|\n",
      "+---+----------------+----------+-----------+-------+------+------+\n",
      "|1  |[Smith, John]   |-1        |2018       |10     |M     |3000  |\n",
      "|2  |[Rose, Mary]    |1         |2010       |20     |M     |4000  |\n",
      "|3  |[Williams, Paul]|1         |2010       |10     |M     |1000  |\n",
      "|4  |[Jones, Joe]    |2         |2005       |10     |F     |2000  |\n",
      "|5  |[Brown, Katie]  |2         |2010       |40     |      |-1    |\n",
      "|6  |[Brown, Justine]|2         |2010       |50     |      |-1    |\n",
      "+---+----------------+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current = [ (1,[\"Smith\", \"John\"],-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "            (2,[\"Rose\", \"Mary\"],1,\"2010\",\"20\",\"M\",4000), \\\n",
    "            (3,[\"Williams\", \"Paul\"],1,\"2010\",\"10\",\"M\",1000), \\\n",
    "            (4,[\"Jones\", \"Joe\"],2,\"2005\",\"10\",\"F\",2000), \\\n",
    "            (5,[\"Brown\", \"Katie\"],2,\"2010\",\"40\",\"\",-1), \\\n",
    "            (6,[\"Brown\", \"Justine\"],2,\"2010\",\"50\",\"\",-1) \\\n",
    "            ]\n",
    "currentColumns = [\"id\",\"full name\",\"superiorid\",\"year_joined\", \"dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "currentDF = spark.createDataFrame(data=current, schema = currentColumns)\n",
    "currentDF.printSchema()\n",
    "cprint(\"--- currentDF Dataset\", \"blue\")\n",
    "currentDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ade3444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m--- previousDF Dataset\u001b[0m\n",
      "+---+-------------------------+----------+-----------+-------+------+------+\n",
      "|id |full name                |superiorid|year_joined|dept_id|gender|salary|\n",
      "+---+-------------------------+----------+-----------+-------+------+------+\n",
      "|1  |[Smith, John]            |-1        |2018       |10     |M     |3000  |\n",
      "|2  |[Rose, Paul]             |1         |2010       |20     |M     |4000  |\n",
      "|3  |[Williams, Mary, Fawcett]|1         |2010       |10     |M     |1000  |\n",
      "|4  |[Jones, Joe]             |2         |2005       |10     |F     |2000  |\n",
      "|5  |[Brown, Katie]           |2         |2010       |40     |      |-1    |\n",
      "|6  |[Brown, Justine]         |2         |2010       |50     |      |-1    |\n",
      "+---+-------------------------+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previous = [ (1,[\"Smith\", \"John\"],-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "            (2,[\"Rose\", \"Paul\"],1,\"2010\",\"20\",\"M\",4000), \\\n",
    "            (3,[\"Williams\", \"Mary\", \"Fawcett\"],1,\"2010\",\"10\",\"M\",1000), \\\n",
    "            (4,[\"Jones\", \"Joe\"],2,\"2005\",\"10\",\"F\",2000), \\\n",
    "            (5,[\"Brown\", \"Katie\"],2,\"2010\",\"40\",\"\",-1), \\\n",
    "            (6,[\"Brown\", \"Justine\"],2,\"2010\",\"50\",\"\",-1) \\\n",
    "            ]\n",
    "previousColumns = [\"id\",\"full name\",\"superiorid\",\"year_joined\", \"dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "previousDF = spark.createDataFrame(data=previous, schema = previousColumns)\n",
    "cprint(\"--- previousDF Dataset\", \"blue\")\n",
    "previousDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "518e01d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------+----------+-----------+-------+------+------+\n",
      "|id |full name                |superiorid|year_joined|dept_id|gender|salary|\n",
      "+---+-------------------------+----------+-----------+-------+------+------+\n",
      "|2  |[Rose, Paul]             |1         |2010       |20     |M     |4000  |\n",
      "|3  |[Williams, Mary, Fawcett]|1         |2010       |10     |M     |1000  |\n",
      "+---+-------------------------+----------+-----------+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test6 = previousDF.subtract(currentDF)\n",
    "df_test6.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448db44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
