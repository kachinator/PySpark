{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Class | Operators & Functions\n",
    "`pyspark.sql.Column` class provides several functions to work with DataFrame to manipulate the Column values, evaluate the boolean expression to filter rows, retrieve a value or part of a value from a DataFrame column, and to work with list, map & struct columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Column\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Column Class Object\n",
    "access the Column from DataFrame by multiple ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name.fname: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(\"James\", 'Male', 23),(\"Ann\", 'Female', 40),(\"Mary\", 'Female', 24)]\n",
    "df=spark.createDataFrame(data).toDF(\"name.fname\",\"gender\", \"Age\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|  Male|\n",
      "|Female|\n",
      "|Female|\n",
      "+------+\n",
      "\n",
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|  Male|\n",
      "|Female|\n",
      "|Female|\n",
      "+------+\n",
      "\n",
      "+----------+\n",
      "|name.fname|\n",
      "+----------+\n",
      "|     James|\n",
      "|       Ann|\n",
      "|      Mary|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.gender).show()\n",
    "df.select(df[\"gender\"]).show()\n",
    "#Accessing column name with dot (with backticks)\n",
    "df.select(df[\"`name.fname`\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|gender|\n",
      "+------+\n",
      "|  Male|\n",
      "|Female|\n",
      "|Female|\n",
      "+------+\n",
      "\n",
      "+----------+\n",
      "|name.fname|\n",
      "+----------+\n",
      "|     James|\n",
      "|       Ann|\n",
      "|      Mary|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using SQL col() function\n",
    "df.select(col(\"gender\")).show()\n",
    "# Accessing column name with dot (with backticks)\n",
    "df.select(col(\"`name.fname`\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- prop: struct (nullable = true)\n",
      " |    |-- hair: string (nullable = true)\n",
      " |    |-- eye: string (nullable = true)\n",
      "\n",
      "+-----+-------------+\n",
      "| name|         prop|\n",
      "+-----+-------------+\n",
      "|James|{black, blue}|\n",
      "|  Ann|{grey, black}|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[Row(name=\"James\",prop=Row(hair=\"black\",eye=\"blue\")),\n",
    "      Row(name=\"Ann\",prop=Row(hair=\"grey\",eye=\"black\"))]\n",
    "df=spark.createDataFrame(data)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|prop.hair|\n",
      "+---------+\n",
      "|    black|\n",
      "|     grey|\n",
      "+---------+\n",
      "\n",
      "+-----+\n",
      "| hair|\n",
      "+-----+\n",
      "|black|\n",
      "| grey|\n",
      "+-----+\n",
      "\n",
      "+-----+\n",
      "| hair|\n",
      "+-----+\n",
      "|black|\n",
      "| grey|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Access struct column\n",
    "df.select(df.prop.hair).show()\n",
    "df.select(df[\"prop.hair\"]).show()\n",
    "df.select(col(\"prop.hair\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| hair|  eye|\n",
      "+-----+-----+\n",
      "|black| blue|\n",
      "| grey|black|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Access all columns from struct\n",
    "df.select(col(\"prop.*\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Column Operators\n",
    "arithmetic operations on columns using operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "| 100|   2|   1|\n",
      "| 200|   3|   4|\n",
      "| 300|   4|   4|\n",
      "+----+----+----+\n",
      "\n",
      "+-------------+\n",
      "|(col1 + col2)|\n",
      "+-------------+\n",
      "|          102|\n",
      "|          203|\n",
      "|          304|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 - col2)|\n",
      "+-------------+\n",
      "|           98|\n",
      "|          197|\n",
      "|          296|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 * col2)|\n",
      "+-------------+\n",
      "|          200|\n",
      "|          600|\n",
      "|         1200|\n",
      "+-------------+\n",
      "\n",
      "+-----------------+\n",
      "|    (col1 / col2)|\n",
      "+-----------------+\n",
      "|             50.0|\n",
      "|66.66666666666667|\n",
      "|             75.0|\n",
      "+-----------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 % col2)|\n",
      "+-------------+\n",
      "|            0|\n",
      "|            2|\n",
      "|            0|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 > col3)|\n",
      "+-------------+\n",
      "|         true|\n",
      "|        false|\n",
      "|        false|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 < col3)|\n",
      "+-------------+\n",
      "|        false|\n",
      "|         true|\n",
      "|        false|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 = col3)|\n",
      "+-------------+\n",
      "|        false|\n",
      "|        false|\n",
      "|         true|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(100,2,1),(200,3,4),(300,4,4)]\n",
    "df=spark.createDataFrame(data).toDF(\"col1\",\"col2\",\"col3\")\n",
    "df.show()\n",
    "\n",
    "#Arthmetic operations\n",
    "df.select(df.col1 + df.col2).show()\n",
    "df.select(df.col1 - df.col2).show() \n",
    "df.select(df.col1 * df.col2).show()\n",
    "df.select(df.col1 / df.col2).show()\n",
    "df.select(df.col1 % df.col2).show()\n",
    "\n",
    "df.select(df.col2 > df.col3).show()\n",
    "df.select(df.col2 < df.col3).show()\n",
    "df.select(df.col2 == df.col3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Functions Examples\n",
    "Dataframe for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  NULL|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| NULL|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(\"James\",\"Bond\",\"100\",None),\n",
    "      (\"Ann\",\"Varsa\",\"200\",'F'),\n",
    "      (\"Tom Cruise\",\"XXX\",\"400\",''),\n",
    "      (\"Tom Brand\",None,\"400\",'M')] \n",
    "\n",
    "columns = [\"fname\",\"lname\",\"id\",\"gender\"]\n",
    "df = spark.createDataFrame(data,columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alias() - Setâ€™s name to Column\n",
    "`df.fname` refers to Column object and `alias()` is a function of the Column to give an alternate name. Here, `fname` column has been changed to `first_name` & `lname` to `last_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     James|     Bond|\n",
      "|       Ann|    Varsa|\n",
      "|Tom Cruise|      XXX|\n",
      "| Tom Brand|     NULL|\n",
      "+----------+---------+\n",
      "\n",
      "+--------------+\n",
      "|      fullName|\n",
      "+--------------+\n",
      "|    James,Bond|\n",
      "|     Ann,Varsa|\n",
      "|Tom Cruise,XXX|\n",
      "|          NULL|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "df.select(df.fname.alias(\"first_name\"), df.lname.alias(\"last_name\")).show()\n",
    "\n",
    "#Another example\n",
    "df.select(expr(\" fname ||','|| lname\").alias(\"fullName\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### asc() & desc() â€“ Sort the DataFrame columns by Ascending or Descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|       Ann|Varsa|200|     F|\n",
      "|     James| Bond|100|  NULL|\n",
      "| Tom Brand| NULL|400|     M|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| NULL|400|     M|\n",
      "|     James| Bond|100|  NULL|\n",
      "|       Ann|Varsa|200|     F|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#asc, desc to sort ascending and descending order repsectively.\n",
    "df.sort(df.fname.asc()).show()\n",
    "df.sort(df.fname.desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cast() & astype() â€“ Used to convert the data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.select(df.fname,df.id.cast(\"int\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  between() â€“ Returns a Boolean expression when a column values in between lower and upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+------+\n",
      "|fname|lname| id|gender|\n",
      "+-----+-----+---+------+\n",
      "|James| Bond|100|  NULL|\n",
      "|  Ann|Varsa|200|     F|\n",
      "+-----+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.id.between(100,300)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contains() â€“ Checks if a DataFrame column value contains a a value specified in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.fname.contains(\"Cruise\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### startswith() & endswith() â€“ Checks if the value of the DataFrame Column starts and ends with a String respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| NULL|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.fname.startswith(\"T\")).show()\n",
    "df.filter(df.fname.endswith(\"Cruise\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### isNull & isNotNull() â€“ Checks if the DataFrame column has NULL or non NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---+------+\n",
      "|    fname|lname| id|gender|\n",
      "+---------+-----+---+------+\n",
      "|Tom Brand| NULL|400|     M|\n",
      "+---------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  NULL|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.lname.isNull()).show()\n",
    "df.filter(df.lname.isNotNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### like() & rlike() â€“ Similar to SQL LIKE expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+\n",
      "|fname|lname| id|\n",
      "+-----+-----+---+\n",
      "|James| Bond|100|\n",
      "+-----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.fname,df.lname,df.id).filter(df.fname.like(\"%es\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### when() & otherwise() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n",
      "|     fname|lname|new_gender|\n",
      "+----------+-----+----------+\n",
      "|     James| Bond|      NULL|\n",
      "|       Ann|Varsa|    Female|\n",
      "|Tom Cruise|  XXX|          |\n",
      "| Tom Brand| NULL|      Male|\n",
      "+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "df.select(df.fname,df.lname,when(df.gender==\"M\",\"Male\") \\\n",
    "              .when(df.gender==\"F\",\"Female\") \\\n",
    "              .when(df.gender==None ,\"\") \\\n",
    "              .otherwise(df.gender).alias(\"new_gender\") \\\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getField() â€“ To get the value by key from MapType column and by stuct child name from StructType column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- fname: string (nullable = true)\n",
      " |    |-- lname: string (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "+-----------------+---------------+-----------------------------+\n",
      "|name             |languages      |properties                   |\n",
      "+-----------------+---------------+-----------------------------+\n",
      "|{James, Bond}    |[Java, C#]     |{eye -> brown, hair -> black}|\n",
      "|{Ann, Varsa}     |[.NET, Python] |{eye -> black, hair -> brown}|\n",
      "|{Tom Cruise, }   |[Python, Scala]|{eye -> grey, hair -> red}   |\n",
      "|{Tom Brand, NULL}|[Perl, Ruby]   |{eye -> blue, hair -> black} |\n",
      "+-----------------+---------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with struct, array & map\n",
    "from pyspark.sql.types import StructType,StructField,StringType,ArrayType,MapType\n",
    "data=[((\"James\",\"Bond\"),[\"Java\",\"C#\"],{'hair':'black','eye':'brown'}),\n",
    "      ((\"Ann\",\"Varsa\"),[\".NET\",\"Python\"],{'hair':'brown','eye':'black'}),\n",
    "      ((\"Tom Cruise\",\"\"),[\"Python\",\"Scala\"],{'hair':'red','eye':'grey'}),\n",
    "      ((\"Tom Brand\",None),[\"Perl\",\"Ruby\"],{'hair':'black','eye':'blue'})]\n",
    "\n",
    "schema = StructType([\n",
    "            StructField('name', StructType([\n",
    "            StructField('fname', StringType(), True),\n",
    "            StructField('lname', StringType(), True)])),\n",
    "            StructField('languages', ArrayType(StringType()),True),\n",
    "            StructField('properties', MapType( StringType(), StringType()),True)\n",
    "         ])\n",
    "df=spark.createDataFrame(data,schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|properties[hair]|\n",
      "+----------------+\n",
      "|           black|\n",
      "|           brown|\n",
      "|             red|\n",
      "|           black|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getField from MapType\n",
    "df.select(df.properties.getField(\"hair\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|name.fname|\n",
      "+----------+\n",
      "|     James|\n",
      "|       Ann|\n",
      "|Tom Cruise|\n",
      "| Tom Brand|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getField from Struct\n",
    "df.select(df.name.getField(\"fname\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getItem() â€“ To get the value by index from MapType or ArrayTupe & ny key for MapType column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|languages[1]|\n",
      "+------------+\n",
      "|          C#|\n",
      "|      Python|\n",
      "|       Scala|\n",
      "|        Ruby|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getItem() used with ArrayType\n",
    "df.select(df.languages.getItem(1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|properties[hair]|\n",
      "+----------------+\n",
      "|           black|\n",
      "|           brown|\n",
      "|             red|\n",
      "|           black|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getItem() used with MapType\n",
    "df.select(df.properties.getItem(\"hair\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- zip: long (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- temperature: long (nullable = true)\n",
      " |-- winds: string (nullable = true)\n",
      "\n",
      "+-----+------+---+----------+-----+------+-----------+-----+\n",
      "| name|gender|Age|      city|  zip|county|temperature|winds|\n",
      "+-----+------+---+----------+-----+------+-----------+-----+\n",
      "|James|  Male| 23|   Wheaton|60187|Dupage|         80|20 SE|\n",
      "|  Ann|Female| 40|Glen Ellyn|60137|Dupage|         78| 21 S|\n",
      "| Mary|Female| 24|    Dekalb|60115|Dekalb|         82| 30 E|\n",
      "+-----+------+---+----------+-----+------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[( \"James\", 'Male', 23, \"Wheaton\", 60187, \"Dupage\", 80, \"20 SE\"),\n",
    "      ( \"Ann\", 'Female', 40, \"Glen Ellyn\", 60137, \"Dupage\", 78, \"21 S\"),\n",
    "      (\"Mary\", 'Female', 24, \"Dekalb\", 60115, \"Dekalb\", 82, \"30 E\")]\n",
    "df=spark.createDataFrame(data).toDF(\"name\",\"gender\", \"Age\", \"city\", \"zip\", \"county\", \"temperature\", \"winds\")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+---------------------------+--------------+------------+----------+\n",
      "|name |conditions |location                   |person        |subjectId   |hot places|\n",
      "+-----+-----------+---------------------------+--------------+------------+----------+\n",
      "|James|{80, 20 SE}|{Wheaton, 60187, Dupage}   |{{Male, 23}}  |James|Dupage|hot       |\n",
      "|Ann  |{78, 21 S} |{Glen Ellyn, 60137, Dupage}|{{Female, 40}}|Ann|Dupage  |cool      |\n",
      "|Mary |{82, 30 E} |{Dekalb, 60115, Dekalb}    |{{Female, 24}}|Mary|Dekalb |hot       |\n",
      "+-----+-----------+---------------------------+--------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,struct,when, concat, lit\n",
    "\n",
    "\n",
    "final = df.select(\"name\", \n",
    "                    struct(col('temperature'), \n",
    "                           col('winds')).alias('conditions'),\n",
    "                    struct(col('city'), \n",
    "                           col('zip'),\n",
    "                           col('county')).alias('location'),\n",
    "                    struct(struct(col('gender'),\n",
    "                                  col('Age')).alias('personType')).alias('person'),\n",
    "                    concat(col('name'), lit(\"|\"), col('County')).alias('subjectId'),\n",
    "                    when(df.temperature>79, 'hot').otherwise('cool').alias('hot places')                      \n",
    "                    )\n",
    "final.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b7f97",
   "metadata": {},
   "source": [
    "`collect_set()` is an aggregate function used to gather unique values from a column within a group into a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b9e0c6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "| name|hot place|\n",
      "+-----+---------+\n",
      "|James|      hot|\n",
      "|  Ann|      hot|\n",
      "|James|     cool|\n",
      "|  Ann|      hot|\n",
      "| Mary|     cool|\n",
      "+-----+---------+\n",
      "\n",
      "+-----+-----------------+\n",
      "| name|unique hot places|\n",
      "+-----+-----------------+\n",
      "|James|      [cool, hot]|\n",
      "|  Ann|            [hot]|\n",
      "| Mary|           [cool]|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_set\n",
    "\n",
    "data_1 = [(\"James\", \"hot\"), (\"Ann\", \"hot\"), (\"James\", \"cool\"), (\"Ann\", \"hot\"), (\"Mary\", \"cool\")]\n",
    "df_2 = spark.createDataFrame(data_1, [\"name\", \"hot place\"])\n",
    "\n",
    "# Group by 'key' and collect unique 'value's into a set\n",
    "result_df_2 = df_2.groupBy(\"name\").agg(collect_set(\"hot place\").alias(\"unique hot places\"))\n",
    "\n",
    "df_2.show()\n",
    "result_df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bacd954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
